model_parameters:
  checkpoint: './models/checkpoints'
  experiment: 'Visual_Transformer'
  device: 'cuda'
  latent_dim: 32
  num_heads: 8
  num_layers: 4
  d_ffn: 512
  n_patches: 7

trainer_parameters:
  lr: 0.0001
  weight_decay: 0.0
  manual_seed: 32  #à changer entre 2 entrainements pour obtenirs des résultats différents
  epochs: 10
  dropout: 0.1 #tester avec 0 de dropout

data_parameters:
  data_path: "./data/MNIST"
  pre_transform: T.NormalizeScale()
  train_batch_size: 128
  val_batch_size:  128
  train_num_points: 2048
  val_num_points: 2048

